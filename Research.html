---
layout: page
title: Research
---

<head>
  <title>Research overview</title>

  <script type="text/x-mathjax-config">
    MathJax.Hub.Config({ tex2jax: {inlineMath: [['$','$'], ['\\(','\\)']]} });
  </script>
  
  <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/MathJax.js?config=TeX-MML-AM_CHTML">
  </script>
  
  <style>
	.project-title {
	  font-size: 20px;
	  display:inline-block;vertical-align:top;
	}
  </style>
  
</head>
<body>

<p>
The overarching objective of my research is to establish provably safe performance capabilities for nonlinear systems under significant uncertainties. 
My Ph.D. thesis mainly involves developing a novel control algorithm starting from its core mathematical underpinnings that is capable of navigating a nonlinear system to a provably
reachable state within a guaranteed set amount of time without knowledge of the system dynamics. We aptly call said algorith Reachable Predictive Control (RPC). To demonstrate the 
algorithm's efficacy, I am currently applying RPC onto an autonomous vehicle with the objective of successfully navigating around obstacles to reach some final state 
within a theoretically guaranteed timeframe without the use of a dynamic model.
</p>
<p>
In addition to the development and application of RPC, current research efforts involve the use of physics informed neural networks (PINNs) to model and control a two-segmented soft 
robotic manipulator and the incorporation of multiple trajectories to perform system identification and control for unknown systems using the Koopman operator. Both efforts fall under
the category of control under significant uncertainties due to the lack of reliable dynamic models for soft robots and the lack of dynamic model needed to control a nonlinear system 
using Koopman operator learning methods.
</p>

  <hr style="margin-top:1cm;">
  <h2>Reachable Predictive Control: A Novel Algorithm for the Control of Unknown Nonlinear Systems without a Dynamics Model</h2>
  
  <p>
   The RPC control algorithm pipeline is presented below: 
  </p>

<head>
  <style>
    figure {
      text-align: center;
      margin: 20px auto;
    }

    figcaption {
      font-style: italic;
      color: #555;
    }
  </style>
</head>
<body>
  <figure>
    <img src="/assets/pictures/FlowChart.png" alt="A description of the image" class="center_img" width="525" height="450">
    <figcaption>Flow Chart of Reachable Predictive Control (RPC).</figcaption>
  </figure>
</body>
  <p>
    RPC works as follows: (1) <b>Resilience Verification:</b> determine if currrent robust and adaptive control methods would provide sufficient
    autonmous capabilities to achieve the control objective; if not, (2) <b>Active Learning:</b> execute a learning cycle to learn the dynamicsT
    locally; (3) <b>Resilient Task Assignment:</b> determine a guaranteed set of reachable states without knowledge of the system dynamics; (4)
    <b>Controller Synthesis:</b> synthesize control action based on the limited knowledge from active learning and resilient task assignment; (5)
    repeat steps (2)-(4) to iteratively navigate to a provably reachable location without knowledge of the true system dynamics.
  </p>
  <p>
    The main idea of our active learning method was first developed in the following <a href="{{ site.baseurl }}/assets/PDFs/Myopic_Control_of_Systems_with_Unknown_Dynamics.pdf" target="_blank">myopic control</a> 
    paper authored by my current advisor, <a href="https://mornik.web.illinois.edu" target="_blank" rel="noopener noreferrer">Prof. Melkior Ornik</a>, and then later built upon in our 
    <a href="{{ site.baseurl }}/assets/PDFs/Online_Learning_and_Control_Synthesis_for_Reachable_Paths_of_Unknown_Nonlinear_Systems_v1.pdf" target="_blank">recently submitted paper</a> currently under review 
    for publication in IEEE Transactions on Automatic Control. These works explain how we may use m+1 actuator excitations learn the dynamics of an unknown system locally around some current initial state, where m is the number of 
    actuators; each series of m+1 excitations is referred to as one learning cycle. We then use the local dynamics and some information on the maximal growth rate of these dynamics to determine a set of 
    provably reachable states for our unknown system during resilient task assignment.  
  </p>

  <p>
    During resilient task assignment, we find an underapproximation of the true reachable set of our unknown system using (i) local dynamics from active learning, and (ii) the growth rate on the bounds of those dynamics 
    gathered from known physical laws. We refer to this set of reachable states as the <a href="{{ site.baseurl }}/assets/PDFs/Reachability_of_Nonlinear_Systems_with_Unknown_Dynamics.pdf" target="_blank"><i>Guaranteed Reachable Set (GRS)</i></a>  
    which intuitively represents a set of states that are <i>provably</i> reachable within an explicit amout of time under extremely limited information. 
    We then optimize results <a href="{{ site.baseurl }}/assets/PDFs/Maximal_Ellipsoid_Method_for_Guaranteed_Reachability_of_Unknown_Fully_Actuated_Systems.pdf" target="_blank">here</a> to maximize the GRS, thereby increasing
    the information we can obtain regarding which states are provably reachable without knowledge of the system dynamics. 
  </p>

  <p>
	We illustrate POLICEd RL below on a simple 2D system and show that safety is guaranteed at the end of training.
	Without the affine policy, TD3 requires several orders of magnitude more training episodes to learn a policy pointing away from the constraint line on its whole length.
	For more details the POLICEd RL paper is accessible <a href="{{ site.baseurl }}/assets/PDFs/POLICEd_RL_ArXiv.pdf" target="_blank" rel="noopener noreferrer">here</a>.
  </p>
	<img src="{{site.baseurl}}/assets/gifs/POLICEd_2D_gif.gif" alt="animated" class="center_img"/> 
	<div class="caption">
		Training of a policy to direct trajectories toward the target (cyan) whithout crossing the constraint line (red).<br>
		The POLICEd policy is affine in the buffer region (green) and learns to push trajectories away from the constraint.
		The black-box dynamics are 2D and continuous, the RL algorithm is TD3.<br>
	</div>	

  
  
  
  
  <hr style="margin-top:1cm;">
  <h2>Resilience of Autonomous Systems</h2>
  
  <p>
	After docking to the International Space Station (ISS), the Nauka module suffered a software error causing its thrusters to misfire.
	In turn, these uncontrolled thrusters rotated the whole space station by 540° before being counteracted by other thrusters of the ISS.
	Motivated by such a scenario, my PhD thesis investigated the guaranteed resilience of autonomous systems to a similar class of malfunctions called partial loss of control authority over actuators.
	These malfunctions are characterized by actuators producing uncontrolled and undesirable outputs instead of following the controller’s commands.
	A loss of control authority can be caused, for instance, by a software bug as in the ISS example or by an adversarial takeover of some actuators of the system.
  </p>
  <p>  
	In this setting, I investigated the malfunctioning system's remaining capabilities to complete its mission in terms of resilient reachability and resilient trajectory tracking.
	I quantified the resilience of linear systems by comparing the reachability performance of the nominal dynamics with that of the worst-case malfunctioning dynamics.
	The resilience of driftless systems is quantified by the Maximax Minimax Quotient Theorem whose geometrical proof is illustrated on the video below.
  </p>	
	 
   <div class="videowrapper">
     <iframe src="https://www.youtube.com/embed/rjKzHyDJX40">
     </iframe>
   </div>
	
  <p>	
	I extended my resilience investigation to systems further inflicted with actuation delays preventing an immediate cancellation of the undesirable outputs.
	I illustrated my theory on a wide range of applications including an octocopter, a fighter jet model, and an orbital inspection mission illustrated by the following video.
  </p>

  <div class="videowrapper">
    <iframe src="https://www.youtube.com/embed/DQy8iNHyt7M">
	</iframe>
  </div>
  
  <p>
	For more details on resilience theory see <a href="{{ site.baseurl }}/assets/blog_posts/resilience">this blog post</a>.
  </p>




  <hr style="margin-top:1cm;">
  <h2>Astrodynamics work</h2>
  
  



  
  <hr style="margin-top:1cm;">
  <h2>Other Research Work</h2>
  
  
  <details>
    <summary>
      <div class="project-title">Transient Safety of Microgrids</div>
	  <div class="github-link">
        <a href="https://github.com/Jean-BaptisteBouvier/Microgrid-transient-safety" target="_blank" rel="noopener noreferrer"><img src="{{site.baseurl}}/assets/logos/GitHub_logo.png" width="25"></a>
      </div>
	</summary>
    <ul>
      <li>To ensure transient safety in inverter-based microgrids, we develop a set invariance-based distributed safety verification algorithm for each inverter module.
	  Applying Nagumo’s invariance condition, we construct a robust polynomial optimization problem to jointly search for safety-admissible set of control set-points and design parameters,
	  under allowable disturbances from neighbors.
	  We use sum-of-squares (SOS) programming to solve the verification problem and we perform numerical simulations using grid-forming inverters to illustrate the algorithm.</li>
      <li>This work has first been presented at the <a href="https://ieeexplore.ieee.org/document/9867323" target="_blank" rel="noopener noreferrer">2022 American Control Conference</a>.</li>
    </ul>

  </details>
  
  
  
  
  
  
<!-- Code to add a button return to top -->
<button onclick="topFunction()" id="topBtn" title="Go to top">Top</button>
<script src="{{ site.baseurl }}/assets/js/top_button.js" ></script>

  
</body>  

